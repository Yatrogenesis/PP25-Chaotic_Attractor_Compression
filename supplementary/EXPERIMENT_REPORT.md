# Experimento de Compresi√≥n de Vectores ML - Reporte Final

**Autor**: Francisco Molina Burgos
**ORCID**: 0009-0008-6093-8267
**Fecha**: 2025-11-21
**Versi√≥n**: 2.0 (Corregida)

---

## Resumen Ejecutivo

Este experimento investig√≥ la efectividad de diferentes algoritmos de compresi√≥n para vectores de embeddings ML (768 dimensiones), espec√≠ficamente evaluando **Delta Encoding** bajo la hip√≥tesis de que deber√≠a lograr ‚â•8x de compresi√≥n con similitud consecutiva ‚â•0.90.

### Hallazgos Principales

1. **‚ùå HIP√ìTESIS REFUTADA**: La implementaci√≥n actual de Delta Encoding NO logr√≥ compresi√≥n efectiva (1.09x-1.10x) incluso con similitud consecutiva muy alta (0.92-0.98)
2. **‚úÖ SESGO IDENTIFICADO Y CORREGIDO**: El experimento inicial generaba vectores con similitud global alta pero similitud consecutiva baja
3. **üèÜ GANADOR**: Int8+GZIP logr√≥ entre 4.61x-10.80x de compresi√≥n, pero con p√©rdida de accuracy variable (1.7%-26%)

---

## Metodolog√≠a

### Correcci√≥n del Sesgo Experimental

**Problema Identificado** (por el usuario):
- Implementaci√≥n inicial: vectores generados con similitud respecto a un vector base GLOBAL
- Resultado: Alta similitud global pero BAJA similitud consecutiva
- Implicaci√≥n: Delta Encoding no puede funcionar sin similitud consecutiva

**Soluci√≥n Implementada**:
Creaci√≥n de 4 datasets con diferentes patrones de similitud consecutiva:

1. **Random Similar (baseline)**: Similitud global, NO consecutiva
2. **Conversational Drift**: Drift acumulativo con similitud consecutiva
3. **Temporal Smoothing**: Promedio m√≥vil exponencial (EMA)
4. **Clustered Topics**: Cambios de tema cada N vectores

### M√©trica Cr√≠tica: Similitud Consecutiva

```rust
/// Similitud coseno promedio entre vectores consecutivos
fn calculate_consecutive_similarity(vectors: &[Vec<f32>]) -> f64 {
    let mut sum = 0.0;
    for i in 1..vectors.len() {
        let a = &vectors[i - 1];
        let b = &vectors[i];
        let cosine_similarity = dot(a, b) / (norm(a) * norm(b));
        sum += cosine_similarity;
    }
    sum / (vectors.len() - 1)
}
```

### M√©todos de Compresi√≥n Evaluados

1. **GZIP Baseline**: Compresi√≥n est√°ndar sin procesamiento
2. **Int8+GZIP**: Cuantizaci√≥n a 8 bits + GZIP
3. **Delta+GZIP**: Diferencias consecutivas + GZIP ‚≠ê (m√©todo bajo prueba)
4. **Zstd**: Compresor moderno de alta eficiencia

---

## Resultados

### Tabla Comparativa por Dataset

| Dataset | Consec.Sim | GZIP | Int8+GZIP | Delta+GZIP | Zstd |
|---------|------------|------|-----------|------------|------|
| Random Similar (baseline) | 0.9185 | 1.13x | 4.62x | 1.09x ‚ö†Ô∏è | 1.12x |
| Conversational Drift ‚≠ê (drift 5%) | 0.9636 | 1.13x | 10.80x | 1.10x ‚ö†Ô∏è | 1.14x |
| Temporal Smoothing (alpha 0.9) | 0.9819 | 1.13x | 4.61x | 1.09x ‚ö†Ô∏è | 1.12x |
| Clustered Topics (100 per cluster) | 0.9199 | 1.12x | 4.58x | 1.09x ‚ö†Ô∏è | 1.12x |

### P√©rdida de Accuracy por Dataset

| Dataset | GZIP | Int8+GZIP | Delta+GZIP | Zstd |
|---------|------|-----------|------------|------|
| Random Similar | 0.0000% | 1.7074% | 0.0000% | 0.0000% |
| Conversational Drift | 0.0000% | 26.1077% | 0.0000% | 0.0000% |
| Temporal Smoothing | 0.0000% | 1.7157% | 0.0000% | 0.0000% |
| Clustered Topics | 0.0000% | 1.7251% | 0.0000% | 0.0000% |

---

## Validaci√≥n de Hip√≥tesis

### Predicci√≥n Original

> **Hip√≥tesis**: Delta Encoding deber√≠a lograr ‚â•8x de compresi√≥n cuando la similitud consecutiva ‚â•0.90

### Resultados por Dataset

#### 1. Random Similar (baseline)
- **Similitud Consecutiva**: 0.9185
- **Delta+GZIP**: 1.09x
- **Evaluaci√≥n**: ‚ùå HIP√ìTESIS REFUTADA (esperaba ‚â•8x con consec.sim ‚â•0.90)

#### 2. Conversational Drift ‚≠ê
- **Similitud Consecutiva**: 0.9636 ‚úÖ EXCELENTE
- **Delta+GZIP**: 1.10x
- **Evaluaci√≥n**: ‚ùå HIP√ìTESIS REFUTADA (esperaba ‚â•8x con consec.sim ‚â•0.90)

#### 3. Temporal Smoothing
- **Similitud Consecutiva**: 0.9819 ‚úÖ EXCELENTE
- **Delta+GZIP**: 1.09x
- **Evaluaci√≥n**: ‚ùå HIP√ìTESIS REFUTADA (esperaba ‚â•8x con consec.sim ‚â•0.90)

#### 4. Clustered Topics
- **Similitud Consecutiva**: 0.9199 ‚úÖ EXCELENTE
- **Delta+GZIP**: 1.09x
- **Evaluaci√≥n**: ‚ùå HIP√ìTESIS REFUTADA (esperaba ‚â•8x con consec.sim ‚â•0.90)

### Resumen de Validaci√≥n

```
Datasets con similitud consecutiva ‚â•0.90 donde Delta valid√≥ (‚â•8x): 0
Datasets con similitud consecutiva ‚â•0.90 donde Delta fall√≥ (<8x): 4
```

**Conclusi√≥n Cient√≠fica**: La implementaci√≥n actual de Delta Encoding **NO FUNCIONA** como se esperaba, incluso con condiciones ideales de similitud consecutiva (hasta 0.98).

---

## An√°lisis de Causa Ra√≠z

### Problema en la Implementaci√≥n de Delta Encoding

Inspecci√≥n del c√≥digo en `src/methods/mod.rs`:

```rust
pub fn delta_decompress(compressed: &[u8]) -> Vec<Vec<f32>> {
    let mut decoder = GzDecoder::new(compressed);
    let mut bytes = Vec::new();
    decoder.read_to_end(&mut bytes).unwrap();

    let floats: Vec<f32> = bytes.chunks_exact(4)
        .map(|chunk| f32::from_le_bytes([chunk[0], chunk[1], chunk[2], chunk[3]]))
        .collect();

    vec![floats]  // ‚ùå BUG: Devuelve UN SOLO vector, no reconstruye N vectores
}
```

**Problema Identificado**:
1. La descompresi√≥n devuelve `vec![floats]` (un solo vector)
2. No reconstruye los N vectores originales a partir de deltas
3. Falta metadata sobre n√∫mero de vectores y dimensiones
4. El algoritmo de reconstrucci√≥n acumulativa no est√° implementado

**Correcci√≥n Necesaria**:
```rust
pub fn delta_decompress(compressed: &[u8]) -> Vec<Vec<f32>> {
    // 1. Deserializar metadata (n_vectors, dim)
    // 2. Reconstruir primer vector
    // 3. Para cada delta: acumular y reconstruir siguiente vector
    // 4. Devolver Vec<Vec<f32>> con N vectores reconstruidos
}
```

---

## Recomendaciones

### Para el Proyecto Lirasion

#### Opci√≥n 1: Int8+GZIP (RECOMENDADO para casos con tolerancia a p√©rdida)

**Ventajas**:
- ‚úÖ Compresi√≥n efectiva: 4.6x-10.8x
- ‚úÖ Ya implementado y funcional
- ‚úÖ R√°pido (cuantizaci√≥n es simple)

**Desventajas**:
- ‚ùå P√©rdida de accuracy variable (1.7%-26%)
- ‚ö†Ô∏è Alto loss en vectores normalizados (26% en Conversational Drift)

**Caso de uso**: Cacheo de embeddings donde se tolera p√©rdida ~2%

#### Opci√≥n 2: Zstd (RECOMENDADO para sin p√©rdida)

**Ventajas**:
- ‚úÖ Sin p√©rdida de accuracy (0.0000%)
- ‚úÖ Compresi√≥n consistente (1.12x-1.14x)
- ‚úÖ R√°pido y eficiente

**Desventajas**:
- ‚ùå Baja compresi√≥n comparada con Int8

**Caso de uso**: Almacenamiento de embeddings donde accuracy es cr√≠tica

#### Opci√≥n 3: Reimplementar Delta Encoding

**Pendiente**:
1. Corregir `delta_decompress()` para reconstruir vectores correctamente
2. Agregar metadata (n_vectors, dim) al formato comprimido
3. Implementar acumulaci√≥n de deltas durante descompresi√≥n
4. Re-ejecutar experimento

**Predicci√≥n**: Si se corrige correctamente, deber√≠a lograr 8x+ con similitud consecutiva ‚â•0.90

#### Opci√≥n 4: PCA+Delta (Alternativa avanzada)

El usuario mencion√≥ "PCA+Delta" en el prompt original:
1. Aplicar PCA para reducir dimensionalidad (768 ‚Üí 128)
2. Aplicar Delta Encoding en espacio reducido
3. Combinar con cuantizaci√≥n

**Ventajas potenciales**:
- Compresi√≥n 6x de PCA + 8x de Delta = 48x te√≥rico
- P√©rdida controlada por componentes principales

---

## C√≥digo Implementado

### Generaci√≥n de Datasets con Similitud Consecutiva

```rust
/// NUEVO: Genera vectores con DRIFT ACUMULATIVO (similitud consecutiva)
fn generate_conversational_drift(n: usize, dim: usize, drift_rate: f64) -> Vec<Vec<f32>> {
    use rand::Rng;
    let mut rng = rand::thread_rng();
    let mut vectors = Vec::new();

    // Primer vector aleatorio
    let mut current: Vec<f32> = (0..dim).map(|_| rng.gen::<f32>()).collect();
    normalize_vector(&mut current);
    vectors.push(current.clone());

    // Siguientes vectores con drift acumulativo
    for _ in 1..n {
        let drift: Vec<f32> = (0..dim).map(|_| rng.gen::<f32>()).collect();
        let mut next = vec![0.0; dim];

        for i in 0..dim {
            next[i] = current[i] * (1.0 - drift_rate as f32) + drift[i] * (drift_rate as f32);
        }

        normalize_vector(&mut next);
        vectors.push(next.clone());
        current = next;  // KEY: drift acumulativo
    }

    vectors
}
```

### M√©trica de Similitud Consecutiva

```rust
fn calculate_consecutive_similarity(vectors: &[Vec<f32>]) -> f64 {
    if vectors.len() < 2 {
        return 0.0;
    }

    let mut sum = 0.0;

    for i in 1..vectors.len() {
        let a = &vectors[i - 1];
        let b = &vectors[i];

        let mut dot = 0.0_f64;
        let mut norm_a = 0.0_f64;
        let mut norm_b = 0.0_f64;

        for j in 0..a.len() {
            dot += (a[j] as f64) * (b[j] as f64);
            norm_a += (a[j] as f64) * (a[j] as f64);
            norm_b += (b[j] as f64) * (b[j] as f64);
        }

        if norm_a > 1e-10 && norm_b > 1e-10 {
            sum += dot / (norm_a.sqrt() * norm_b.sqrt());
        }
    }

    sum / ((vectors.len() - 1) as f64)
}
```

---

## Archivos Generados

- **`results/results_all_similarities.json`**: Resultados completos en JSON
- **Salida de consola**: Tabla comparativa y validaci√≥n de hip√≥tesis

---

## Pr√≥ximos Pasos

1. **INMEDIATO**: Decidir qu√© m√©todo usar en Lirasion ML
   - Int8+GZIP si se tolera ~2% p√©rdida
   - Zstd si se requiere sin p√©rdida

2. **CORTO PLAZO**: Reimplementar Delta Encoding correctamente
   - Corregir `delta_decompress()`
   - Re-ejecutar experimento
   - Validar si logra ‚â•8x esperado

3. **MEDIANO PLAZO**: Investigar PCA+Delta
   - Implementar reducci√≥n dimensional
   - Combinar con Delta/Int8
   - Evaluar trade-off compresi√≥n vs accuracy

---

## Referencias

- **IIT 3.0**: Tononi et al., 2016 - Integrated Information Theory
- **Delta Encoding**: T√©cnica cl√°sica de compresi√≥n por diferencias
- **Zstd**: Facebook's Zstandard compression algorithm

---

## Ap√©ndice: Salida Completa del Experimento

```
üî¨ Experimento de Compresi√≥n de Vectores - CORREGIDO
Autor: Francisco Molina Burgos (ORCID: 0009-0008-6093-8267)
Fecha: 2025-11-21
Versi√≥n: 2.0 - Con similitud consecutiva

======================================================================
üìä Testing: Random Similar (baseline)
======================================================================

üîë Similitud Consecutiva: 0.9185
   ‚ö†Ô∏è  MEDIA - Delta Encoding puede funcionar parcialmente

Testing GZIP Baseline...
Testing Int8 Quantization...
Testing Delta Encoding...
Testing Zstd...

üìä Resultados:
  GZIP           : ratio= 1.13x, comp= 93.21ms, decomp= 6.75ms, loss=0.0000%
  Int8+GZIP      : ratio= 4.62x, comp= 99.93ms, decomp= 6.88ms, loss=1.7074%
  Delta+GZIP     : ratio= 1.09x, comp=100.18ms, decomp= 6.12ms, loss=0.0000% ‚ö†Ô∏è (esperaba ‚â•8x)
  Zstd           : ratio= 1.12x, comp= 19.51ms, decomp= 1.26ms, loss=0.0000%

üî¨ Validaci√≥n de Hip√≥tesis:
   ‚ùå HIP√ìTESIS REFUTADA: Delta solo 1.09x (esperaba ‚â•8x) con similitud 0.9185

[... 3 datasets m√°s con resultados similares ...]

üìä TABLA COMPARATIVA FINAL
[ver tabla en secci√≥n Resultados]

üèÜ VALIDACI√ìN DE HIP√ìTESIS Y CONCLUSIONES

‚ùå CONCLUSI√ìN: Implementaci√≥n actual de Delta Encoding NO funciona como esperado.
   Revisar algoritmo o considerar alternativas (PCA+Delta, etc.).
```

---

**Fin del Reporte**
